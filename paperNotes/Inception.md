Inceptionç³»åˆ—æœ‰å››ç¯‡é‡è¦çš„paperï¼Œåˆ†åˆ«æ˜¯ï¼š[Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842)ã€
[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shif](https://arxiv.org/abs/1502.03167)ã€[Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567)ã€[Inception-v4](https://arxiv.org/abs/1602.07261)
åœ¨æ­¤ï¼Œä¾æ¬¡é˜…è¯»å¹¶åšç¬”è®°ã€‚
## GoogleNet
### Introduction & Motivation
[Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842) é¦–æ¬¡æå‡ºäº†ã€Œ**Inception**ã€æ¨¡å—ä½œä¸ºç½‘ç»œæ„æ¶ï¼Œ
è¯¥ç½‘ç»œæ„æ¶ä¹Ÿæ˜¯åç»­ä½œä¸ºclassificationå’Œdetectionçš„base networkçš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚
> we introduce a new level of organization in the form of the "Inception module" and also in a more direct sense of increased
network depth.  

ç½‘ç»œçš„sizeä¸»è¦ä»ä¸¤æ–¹é¢è¿›è¡Œè€ƒè™‘ï¼šdepth - the number of levels - of the network å’Œ width - the number of units at each levelã€‚ã€ŒåŠ æ·±ç½‘ç»œdepthã€ã€ã€Œè°ƒèŠ‚è¶…å‚æ•°ã€å¯ä»¥åœ¨recognitionå’Œobject detectionå–å¾—æ›´å¥½çš„æ•ˆæœã€‚ä½†æ˜¯ç½‘ç»œçš„sizeè¿‡å¤§ï¼Œä¼šç›´æ¥å½±å“è¿è¡Œçš„æ€§èƒ½ã€‚å°±åƒä¸€ä¸ªäººè¿‡èƒ–ï¼Œä¼šç›´æ¥å½±å“èº«ä½“å¥åº·ã€‚å½“ç½‘ç»œçš„sizeè¿‡å¤§çš„æ—¶å€™ï¼Œå‚æ•°#paramtersè¿‡å¤šï¼Œæ¶ˆè€—çš„è®¡ç®—èµ„æºå°±è¶Šå¤šï¼Œæ­¤å¤–ï¼Œç‰¹åˆ«æ˜¯åœ¨labeled exampleså¾ˆæœ‰é™çš„æƒ…å†µä¸‹ï¼Œæ›´å®¹æ˜“å‡ºç°overfittingã€‚ä¸€èˆ¬æ˜¯é‡‡ç”¨ã€Œdropoutã€æˆ–è€…ã€Œregularizationã€ï¼Œå¹¶ä¸”ã€Œè°ƒæ•´è¶…å‚æ•°ã€å’Œã€Œè®¾ç½®å­¦ä¹ ç‡ã€å»é˜²æ­¢è®­ç»ƒè¿‡ç¨‹ä¸­è¿‡æ‹Ÿåˆç°è±¡çš„å‡ºç°ã€‚
> For larger datasets such as Imagenet, deeper architectures are used to get better results and dropout is used to prevent
overfitting â€¦â€¦ Since in practice the computational budget is always finite, an efficient distribution of computing resources is preferred to an indiscriminate increase of sizeã€‚  

### Inception module
ä¸Šé¢çš„æ–¹æ³•æŒºå¥½çš„ï¼Œä½†ä¹ŸæŒºè›®çƒ¦çš„ï¼Œæ‰€ä»¥ä½œè€…è¯•å›¾ç»“åˆã€Œæ•°æ®ç»“æ„ã€ç½‘ç»œç»“æ„ã€æ¥è€ƒè™‘ï¼Œå¦‚ä½•è®¾è®¡ä¸€ä¸ªåˆ›æ–°æ€§çš„architectureï¼Œæ¥æ›´å¥½çš„åˆ©ç”¨è®¡ç®—èµ„æºä»¥åŠç¨å¾®æ”¾å¿ƒã€å¤§èƒ†çš„è®¾ç½®å‚æ•°ä¸€äº›?

é¦–å…ˆï¼Œå¼€ä¸ªå°åˆ†æ”¯ï¼Œä»‹ç»ä¸€ä¸‹ã€Œç¨€ç–ç»“æ„ã€çš„ç†è®ºåŸºç¡€ï¼š**HebbianåŸç†**ã€‚ ä½œè€…ä»neuroscienceçš„è§’åº¦å¾—åˆ°äº†å¯å‘ï¼Œæå‡ºäº†ç½‘ç»œç»“æ„çš„åˆ›æ–°ï¼šã€‚
è¯¥åŸç†æŒ‡å‡ºï¼šå„ä¸ªç¥ç»å…ƒæ˜¯ç»„åˆæ•ˆåº”ï¼Œé€šè¿‡ç¥ç»çªè§¦è¿›è¡Œä¿¡æ¯çš„ä¼ é€’ï¼Œå¤§è„‘çš®å±‚æ¥æ”¶ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œ
ç¥ç»åå°„æ´»åŠ¨çš„æŒç»­ä¸é‡å¤ä¼šå¯¼è‡´ç¥ç»å…ƒè¿æ¥ç¨³å®šæ€§çš„æŒä¹…æå‡ï¼Œå½“ä¸¤ä¸ªç¥ç»å…ƒç»†èƒAå’ŒBè·ç¦»å¾ˆè¿‘ï¼Œå¹¶ä¸”Aå‚ä¸äº†å¯¹Bé‡å¤ã€æŒç»­çš„å…´å¥‹ï¼Œé‚£ä¹ˆæŸäº›ä»£è°¢å˜åŒ–ä¼šå¯¼è‡´Aå°†ä½œä¸ºèƒ½ä½¿Bå…´å¥‹çš„ç»†èƒã€‚
> neurons that fire together, wire together.
å°†Fully Connectedå˜ä¸ºç¨€ç–è¿æ¥ï¼ˆsparse connectionï¼‰çš„æ—¶å€™ï¼Œå¯ä»¥åœ¨å¢åŠ ç½‘ç»œæ·±åº¦å’Œå®½åº¦çš„åŒæ—¶å‡å°‘å‚æ•°ä¸ªæ•°ï¼Œ
ä½†æ˜¯å¤§éƒ¨åˆ†çš„ç¡¬ä»¶æ˜¯é’ˆå¯¹å¯†é›†çŸ©é˜µè®¡ç®—ä¼˜åŒ–çš„ï¼Œç¨€ç–çŸ©é˜µè™½ç„¶æ•°æ®é‡å˜å°‘ï¼Œä½†è®¡ç®—æ‰€æ¶ˆè€—çš„æ—¶é—´å¾ˆéš¾å‡å°‘ã€‚
GoogleNetå¸Œæœ›åšçš„å°±æ˜¯æ—¢ä¿è¯ç½‘ç»œç»“æ„çš„ç¨€ç–æ€§ã€åˆåˆ©ç”¨å¯†é›†çŸ©é˜µçš„é«˜è®¡ç®—æ€§èƒ½ã€‚

GoogleNetçš„æ ¸å¿ƒæ˜¯Inception moduleï¼Œè€ŒInceptionç›¸å½“äºä¸€ä¸ªConvolutional building blockï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå±€éƒ¨ç¨€ç–æœ€ä¼˜è§£çš„ç½‘ç»œæ„æ¶ï¼Œç„¶åæˆ‘ä»¬åœ¨
ç©ºé—´ä¸Šåšå †å ã€‚ä¸‹é¢æˆ‘ä»¬ç»“åˆè®ºæ–‡çš„æ’å›¾æ¥ä»”ç»†åˆ†æä¸€ä¸‹Inception moduleã€‚å›¾aæ˜¯åŸå§‹çš„Inception moduleï¼Œå›¾bæ˜¯å€Ÿé‰´äº†NINï¼ˆNetwork In Networkï¼‰
å¼•å…¥1x1çš„å·ç§¯æ“ä½œï¼Œæ”¹è¿›åçš„Inception moduleã€‚
> Our network will be built from convolutional building blocks.
All we need is to find the **optimal local construction** and to repeat it spatially.   

![1](https://cdn-images-1.medium.com/max/2000/1*aq4tcBl9t5Z36kTDeZSOHA.png)  

è¾“å…¥æœ‰å››ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨å¤šä¸ªå°ºåº¦ï¼ˆ1x1æˆ–3x3æˆ–5x5ï¼‰çš„å·ç§¯å’Œæ± åŒ–è¿›è¡Œç‰¹å¾æå–ã€Œç›¸å½“äºå°†ç¨€ç–çŸ©é˜µåˆ†è§£ä¸ºå¯†é›†çŸ©é˜µã€ï¼Œæ¯ä¸€å°ºåº¦æå–çš„ç‰¹å¾æ˜¯å‡åŒ€åˆ†å¸ƒçš„ï¼Œ
ä½†æ˜¯ç»è¿‡ã€Œfilter concatenationã€è¿™æ­¥æ“ä½œåï¼Œè¾“å‡ºçš„ç‰¹å¾ä¸å†æ˜¯å‡åŒ€åˆ†å¸ƒçš„ï¼Œ**ç›¸å…³æ€§å¼ºçš„ç‰¹å¾ä¼šè¢«åŠ å¼ºï¼Œè€Œç›¸å…³æ€§å¼±çš„ç‰¹å¾ä¼šè¢«å¼±åŒ–**ã€‚*è¿™ä¸ªç›¸å…³æ€§é«˜çš„èŠ‚ç‚¹åº”è¯¥è¢«è¿æ¥åœ¨ä¸€èµ·çš„ç»“è®ºï¼Œå³æ˜¯ä»ç¥ç»ç½‘ç»œçš„è§’åº¦å¯¹HebbianåŸç†æœ‰æ•ˆæ€§çš„è¯æ˜*
ã€Œfilter concatenationã€ï¼Œè¿™ä¸€æ­¥å…¶å®ç›¸å½“äºæ²¿ç€æ·±åº¦æ–¹å‘ï¼ˆæˆ–è€…è¯´åœ¨depthè¿™ä¸ªç»´åº¦ï¼‰è¿›è¡Œæ‹¼æ¥ï¼Œ
> stack up the first volume to the second volume to make the dimensions match up â€¦â€¦ Output a single output vector forming the input of 
next stageã€‚  

ç»“åˆ[Udacityè§†é¢‘](https://becominghuman.ai/understanding-and-coding-inception-module-in-keras-eb56e9056b4b)å’Œcodeæ¥åŠ æ·±ä¸€ä¸‹å¯¹ã€Œfilter concatenationã€çš„ç†è§£
> 
    concatenated_tensor = tf.concat(3,[branch1, branch2, branch3, branch 4])  


**E.g:**   
{General}ï¼šè¾“å…¥ 28x28x192 volume ï¼Œå¹¶åˆ—ç»è¿‡ 1x1å·ç§¯æ“ä½œã€3x3å·ç§¯æ“ä½œã€5x5å·ç§¯æ“ä½œã€max-poolï¼Œåˆ†åˆ«å¾—åˆ°28x28x64ã€28x28x128ã€
28x28x32ã€28x28x32 volume, å°†å¹¶åˆ—çš„volumeæ²¿ç€æ·±åº¦æ–¹å‘è¿›è¡Œæ‹¼æ¥ï¼Œè¾“å‡º 28x28x256 volumeã€‚ 
> Feifei-Liçš„cs231nçš„è¯¾ä»¶é‡Œæ˜¯æè¿°CNNçš„ï¼ševery layer of a ConvNet transforms one volume of activations to another through a differentiable function.We use three main types of layers to build ConvNet architectures:Convolutional Layer, Pooling Layer,
and Fully-Connected Layer.  Conv layer will compute **the output of neurons** that are connected to local regions in the input,
each computing a **dot product between their weights** and a small region they are connected to the input volume.
Pool layer will perform a downsampling operation along **the spatial dimensions**(*width,height*)
FC layer will compute the class score,resulting in volume of sizeã€Œ1x1x#classã€ã€‚

{Specific}ï¼š5x5çš„å·ç§¯æ“ä½œå¾—åˆ°äº†28x28x32çš„blockã€‚
filter size =5x5x192ï¼Œ5 pixels width and height, 192 pixels depthï¼ˆfilterçš„æ·±åº¦éœ€è¦å’Œ*å‰ä¸€feature mapçš„æ·±åº¦*ä¿æŒä¸€è‡´ã€‚ï¼‰


è®¾input volume width = W,  the width of receptive field = F_w, zero padding on the border = P, stride = S
é‚£ä¹ˆoutput volume width = (W-F+2P)/S+1ã€‚åŒç†ä¹Ÿå¯ä»¥å¾—åˆ°output volume heightã€‚æ­¤å¤–, input volume depth = D1
æ­¤å¤–ï¼Œè¢«filterè¦†ç›–çš„å›¾åƒåŒºåŸŸç§°ä¸ºreceptive fieldï¼Œå…·ä½“æ“ä½œæ˜¯ï¼šslide each filter across the width and height of the input volume and compute dot products between the entries of the filter and the input at any positionï¼Œå³filterä¸­çš„å€¼å’ŒåŸå§‹å›¾åƒä¸­receptive fieldä¸­çš„åƒç´ å€¼è¿›è¡Œç‚¹ç§¯è¿ç®—ï¼Œäº§ç”Ÿactivation mapæˆ–feature mapã€‚**å›¾åƒä¸€èˆ¬éƒ½æ˜¯å±€éƒ¨ç›¸å…³çš„**ï¼Œ
ç¬¬n+1å±‚çš„æ¯ä¸ªç¥ç»å…ƒå’Œç¬¬nå±‚çš„receptive fieldä¸­çš„ç¥ç»å…ƒè¿æ¥ï¼Œè€Œä¸éœ€è¦å’Œç¬¬nå±‚çš„æ‰€æœ‰ç¥ç»å…ƒè¿æ¥ï¼ŒConvNetå…·æœ‰**local connectivity(å±€éƒ¨è¿æ¥)** çš„æ€§è´¨ã€‚å½“filterçš„receptive fieldè¶Šå¤§ï¼Œfilterèƒ½å¤Ÿå¤„ç†çš„åŸå§‹è¾“å…¥å†…å®¹çš„èŒƒå›´å°±è¶Šå¤§ã€‚éšç€ç»è¿‡æ›´å¤šçš„å·ç§¯å±‚ï¼Œå¾—åˆ°çš„æ¿€æ´»æ˜ å°„ä¹Ÿå°±å…·æœ‰æ›´ä¸ºå¤æ‚çš„ç‰¹å¾ã€‚  

![4](http://cs231n.github.io/assets/cnn/depthcol.jpeg)

è®¾ number of filters = K, ä¹Ÿæ˜¯output volume depthçš„å€¼ã€‚å½“filterçš„æ•°ç›®è¶Šå¤šï¼Œspatial dimensionså°±ä¼šä¿ç•™çš„è¶Šå¥½ã€‚
CNNå…·æœ‰local connectionå’Œparameter sharingçš„ç‰¹ç‚¹ã€‚
æ¯ä¸ªfilterçš„æƒé‡çš„ä¸ªæ•° = F_w x F_h x D1, æ€»çš„æƒé‡ä¸ªæ•°= F_w x F_h x D1 x K

æˆ‘ä»¬å†åˆ†æä¸€ä¸‹**compution cost**
> cs231n æŒ‡å‡ºï¼š the largest bottleneck to be aware of when constructing the ConvNet is the memory bottle neck.
we need to keep track of the intermediate volume size, the paramter size and the memory.
[Reference:cs231n](http://cs231n.github.io/convolutional-networks/#conv)  

ç°åœ¨æˆ‘ä»¬æ¥åˆ†æä¸€ä¸‹ï¼Œä¸Šé¢çš„å›¾bç›¸æ¯”å›¾açš„ä¼˜åŠ¿åœ¨å“ªé‡ŒğŸ§ã€‚  
1x1çš„å·ç§¯æ˜¯ä½œä¸ºç“¶é¢ˆå±‚çš„ä½œç”¨ï¼Œç”¨å¾ˆå°çš„è®¡ç®—é‡å¯ä»¥å¢åŠ ä¸€å±‚ç‰¹å¾å˜æ¢å’Œéçº¿æ€§å˜æ¢ã€‚*æ­¤å¤–ï¼Œä¸€èˆ¬æ¶‰åŠåˆ°æ”¹å˜é€šé“æ•°ï¼Œéƒ½ä¼šä½¿ç”¨1x1å·ç§¯æ“ä½œï¼Œ
ä¾‹å¦‚æ®‹å·®è¿æ¥å’ŒDenseè¿æ¥*  
> the bottleneck is usually the smallest part of something
æˆ‘ä»¬æ¥è®¡ç®—ä¸€ä¸‹å›¾aä¸­5x5çš„å·ç§¯æ“ä½œå¾—åˆ°äº†28x28x32çš„blockçš„æ—¶å€™ï¼Œæ‰€éœ€è¦çš„multiplesçš„æ¬¡æ•°ã€‚ä»¥åŠå›¾bä¸­å…ˆä½¿ç”¨1x1çš„å·ç§¯æ“ä½œå…ˆå¾—åˆ°28x28x16ï¼Œå†ä½¿ç”¨5x5çš„å·ç§¯æ“ä½œå¾—åˆ°äº†28x28x32çš„blcokçš„æ—¶å€™ï¼Œæ‰€éœ€è¦çš„multiplesçš„æ¬¡æ•°ã€‚  


1.å›¾a (28x28x32) x (5x5x192) = 120million ã€Œä¸€ä¸ªoutput volumeæ‰€éœ€è¦çš„ä¹˜ç§¯æ¬¡æ•° x the number of output valuesã€ 

2.å›¾b ï¼ˆ28x28x16) x (1x1x192) + (28x28x32) x (5x5x16) = 12.4 million  

ä»ä¸Šé¢ğŸ‘†ä¸¤ä¸ªå¯¹æ¯”å¯ä»¥çŸ¥é“1x1çš„å·ç§¯æ“ä½œå¤§å¤§çš„å‡å°‘äº†è®¡ç®—é‡ã€‚


### GoogleNet's architecture
é¦–å…ˆï¼Œä¸ºäº†æœ‰ä¸€ä¸ªåˆæ­¥çš„å°è±¡ï¼Œå…ˆæˆªå–äº†GoogleNetçš„ä¸€éƒ¨åˆ†ï¼Œ
![2](https://mohitjainweb.files.wordpress.com/2018/06/googlenet-architecture-showing-the-side-connection.png?w=700)  
æˆ‘ä»¬å¯ä»¥æ³¨æ„åˆ°è¿™é‡Œæœ‰ä¸€ä¸ªã€Œsoftmaxã€çš„åˆ†æ”¯ï¼Œæ•´ä¸ªç»“æ„ä¸­æœ‰ä¸¤ä¸ªã€Œsoftmaxã€ï¼Œå®ƒç›¸å½“äºè¾…åŠ©åˆ†ç±»å™¨ï¼Œç»“åˆcodeæˆ‘ä»¬å¯ä»¥çŸ¥é“è¯¥æ“ä½œæ˜¯å°†ä¸­é—´æŸä¸€å±‚çš„è¾“å‡ºç”¨ä½œåˆ†ç±»ï¼Œå¹¶æŒ‰ä¸€ä¸ªè¾ƒå°çš„æƒé‡ï¼ˆ0.3ï¼‰åŠ åˆ°æœ€ç»ˆåˆ†ç±»ç»“æœä¸­èµ·åˆ°çš„æ˜¯æ¢¯åº¦å‰å‘ä¼ è¾“çš„ä½œç”¨ã€‚è®ºæ–‡é‡Œæ˜¯è¿™ä¹ˆäº¤ä»£çš„ï¼š
> By adding auxiliary classifiers connected to these intermediate layers, we would expect to encourage discrimination in the lower stages in the classifier, increase the gradient signal that gets propagated back, and provide additional regularization.  

å…¶æ¬¡ï¼Œä¸ºäº†å¯¹GoogleNetçš„ç»„æˆæœ‰ä¸€ä¸ªæ¦‚å¿µï¼Œå¼•ç”¨äº†è®ºæ–‡ä¸­çš„è¡¨æ ¼ï¼š
![3](https://img-blog.csdn.net/20170612110458444?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbWFyc2poYW8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
ä¸Šé¢è®¨è®ºæ—¶ï¼Œå·²ç»è¯´è¿‡GoogleNetæ˜¯æ¨¡å—åŒ–çš„ï¼Œå †å äº†å¤šä¸ªInception Moduleï¼Œé åçš„Inception Moduleèƒ½å¤ŸæŠ½å–æ›´é«˜é˜¶çš„æŠ½è±¡çš„ç‰¹å¾ã€‚

