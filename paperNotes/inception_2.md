## Batch Normalization
### Internal covariate shift
"Internal"æŒ‡çš„æ˜¯ç¥žç»ç½‘ç»œçš„éšå«å±‚ï¼Œ"Covariate"æŒ‡çš„æ˜¯è¾“å…¥çš„æƒé‡å‚æ•°åŒ–ï¼Œâ€œInternal Covariate Shiftâ€æŒ‡çš„æ˜¯
åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œè¾“å…¥çš„æ¦‚çŽ‡åˆ†å¸ƒä¸å›ºå®šï¼Œç½‘ç»œçš„å‚æ•°åœ¨ä¸æ–­çš„å˜åŒ–ï¼Œç¥žç»ç½‘ç»œçš„éšå«å±‚ä¹Ÿè¦ä¸æ–­çš„åŽ»ã€Œé€‚åº”ã€æ–°çš„åˆ†å¸ƒã€‚
è¿™ä¸ªçŽ°è±¡ä¼šè®©æ¨¡åž‹æ›´åŠ éš¾è®­ç»ƒï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦æ›´åŠ è°¨æ…Žçš„åˆå§‹åŒ–æ¨¡åž‹å‚æ•°å’Œå­¦ä¹ çŽ‡ã€‚å› æ­¤ä½œè€…å¼•å…¥äº†*Normalization* æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ 

BNçš„åŸºæœ¬æ€æƒ³å°±æ˜¯ï¼šè®©æ¯ä¸ªéšå±‚èŠ‚ç‚¹çš„æ¿€æ´»è¾“å…¥åˆ†å¸ƒå›ºå®šä¸‹æ¥ï¼Œé€šè¿‡è§„èŒƒåŒ–çš„æ‰‹æ®µï¼Œå°†æ¯å±‚ç¥žç»ç½‘ç»œä»»æ„
ç¥žç»å…ƒè¿™ä¸ªè¾“å…¥å€¼çš„åˆ†å¸ƒâ€œå¼ºè¡Œæ‹‰å›žâ€åˆ°å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1çš„åˆ†å¸ƒä¸­ã€‚éœ€è¦ã€Œå›ºå®šã€å‚æ•°çš„åŽŸå› ï¼Œåœ¨paperé‡Œæ˜¯è¿™ä¹ˆäº¤ä»£çš„ã€‚
> the inputs to each layer are affected by the parameters of all preceding layers - so that small
changes to the network parameters amplify as the network becomes deeper â€¦â€¦ Fixed distribution of inputs to a 
sub-network would have a positive consequences for the layers outside the network, as well.
### Normalization
å¸¸è§„çš„æ­£åˆ™åŒ–å…¬å¼ä¸ºï¼š\mathbf{\hat{x}^{(k)} }=\mathbf{(x^{k}-E[x^{k}])/ \sqrt{var(x^{k})}} 

ç»è¿‡BNåŽï¼Œå¤§éƒ¨åˆ†çš„activationçš„å€¼å°±ä¼šè½å…¥éžçº¿æ€§å‡½æ•°çš„ã€Œçº¿æ€§åŒºåŸŸã€å³ã€Œå¯¼æ•°éžé¥±å’ŒåŒºåŸŸã€ï¼Œ
è¿™æ ·å°±å¯ä»¥é¿å…è¿›å…¥æ¢¯åº¦é¥±å’ŒåŒºåŸŸ(å³*æ¢¯åº¦å˜åŒ–è¾ƒå°çš„åŒºåŸŸ*)ï¼Œè¿™æ ·çš„è¯ï¼Œè®­ç»ƒæ—¶å°±å¯ä»¥åŠ å¿«æ”¶æ•›é€Ÿåº¦ã€‚

## Rethinking the Inception Architecture for Computer vision
å› ä¸ºè®¡ç®—å¼€é”€ã€å‚æ•°é‡é™åˆ¶äº†æŠŠInceptionéƒ¨ç½²åˆ°ç§»åŠ¨ç«¯å’Œä¸€äº›åœºæ™¯ä¸­ï¼Œåœ¨abstracté‡Œï¼Œä½œè€…æŒ‡å‡ºäº†å¯¹ç½‘ç»œæž„æž¶è¿›è¡Œæ”¹è¿›çš„æ€è·¯ã€‚
> Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by **factorized convolutions and aggressive regularization**.
### å·ç§¯æ ¸çš„å› å¼åˆ†è§£
Paperé‡ŒæŽ¢ç´¢äº†å‡ å¼ å°†è¾ƒå¤§çš„å·ç§¯æ ¸åˆ†è§£ä¸ºè¾ƒå°çš„å·ç§¯æ ¸çš„è®¾ç½®æ–¹å¼ã€‚ä¾‹å¦‚ï¼š5x5çš„å·ç§¯æ ¸æ›¿æ¢ä¸ºä¸¤ä¸ª3x3çš„å·ç§¯æ ¸ï¼›3x3çš„å·ç§¯æ ¸æ›¿æ¢ä¸º1x3å’Œ3x1çš„å·ç§¯æ ¸ã€‚è¿™æ ·å…·æœ‰ç›¸åŒçš„receptive fieldçš„åŒæ—¶å¯ä»¥å¤§å¤§çš„å‡å°è®¡ç®—å¼€é”€ã€‚

![1](https://tse2.mm.bing.net/th?id=OIP.lEHUl5w_rweJSb-FpNdKeAHaFl&pid=Api)  

![2](http://davidstutz.de/wordpress/wp-content/uploads/2017/03/inception_arch_3.png)  

éœ€è¦æ³¨æ„çš„æ˜¯ã€Œnxnçš„å·ç§¯è¢«æ›¿æ¢ä¸º1xnå’Œnx1çš„å·ç§¯ã€çš„è¿™ç§ç©ºé—´ä¸Šåˆ†è§£ä¸ºéžå¯¹ç§°å·ç§¯çš„åšæ³•åœ¨å‰é¢å‡ å±‚layerçš„æ•ˆæžœä¸æ˜¯å¾ˆå¥½ï¼Œæ›´é€‚ç”¨äºŽä¸­ç­‰è§„æ ¼å¤§å°çš„feature mapï¼Œï¼ˆmçš„èŒƒå›´ä»Ž12åˆ°20ï¼‰ã€‚
æ­¤å¤–æˆ‘ä»¬è¿˜è¦æ€è€ƒðŸ¤”å‡ ä¸ªé—®é¢˜ã€‚  
1.ç”¨å°å·ç§¯æ ¸æ›¿æ¢å¤§å·ç§¯æ ¸ï¼Œæ˜¯å¦ä¼šå¸¦æ¥ä¿¡æ¯æŸå¤±(loss of expressiveness)? ä¸ä¼šï¼Œåªè¦å¤šæ¬¡å åŠ çš„å°å·ç§¯æ ¸å’Œå¼€å§‹çš„å¤§å·ç§¯æ ¸å…·æœ‰ç›¸åŒçš„receptive fieldã€‚  
2.å¦‚æžœæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å¯¹è®¡ç®—å¼€é”€ä¸­çš„çº¿æ€§éƒ¨åˆ†è¿›è¡Œå› å¼åˆ†è§£ï¼Œé‚£ä¹ˆä¸ºä»€ä¹ˆä¸ç›´æŽ¥åœ¨ç¬¬ä¸€æ¬¡ä¿æŒçº¿æ€§æ¿€æ´»ï¼ˆlinear activationï¼‰ï¼Ÿå› ä¸ºåœ¨å®žéªŒä¸­è¡¨æ˜Žï¼Œéžçº¿æ€§æ¿€æ´»æ€§èƒ½æ›´å¥½ã€‚
 

### Label Smoothing Regularization
å› ä¸ºå¤§å¤šæ•°çš„æ•°æ®é›†éƒ½å­˜åœ¨é”™è¯¯çš„æ ‡ç­¾ï¼Œ ä½†æ˜¯minimize the cost function on the wrong labels can be harmfulã€‚å› æ­¤åœ¨Model Regularizationä¸­ï¼Œå¯ä»¥é€šè¿‡åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ä¸»åŠ¨åŠ å…¥å™ªå£°ä½œä¸ºpenaltyï¼Œè¿™æ ·çš„æ¨¡åž‹å…·æœ‰noise Robustnessã€‚Label Smoothing Regularization(LSR)æ˜¯å…¶ä¸­çš„ä¸€ç§regularizationçš„æ–¹æ³•ã€‚
> Here we propose a mechanism to regularize the classifier layer by estimating the marginalized effect of label-dropout during
training.   

{*ä¸¾ä¸€ä¸ªUniversity of Waterlooçš„WAVE LABçš„ ME 780ä¸­lecture 3ï¼šRegularization for deep modelsçš„ä¾‹å­æ¥å¸®åŠ©ç†è§£*ï¼š  
*ground-truth:*   y1_label=[1,0,0,â€¦â€¦ï¼Œ0]  
*prediction:*   ç»è¿‡softmax classifierå¾—åˆ°çš„softmax output:  y1_out=[0.87,0.001,0.04â€¦â€¦,0.03]. }  
> maximum likelihood learning with softmax classifier and hard targets may actually never converge, the softmax can 
never predict a probability of exactly 0 or 1, so it will continue to learn larger and larger weights, making more 
extreme predictions.  


å‡è®¾xä¸ºtraining exampleï¼Œp(k|x)ä¸ºxå±žäºŽã€Œlabel kã€çš„æ¦‚çŽ‡ï¼Œq(k|x)ä¸ºxå±žäºŽã€Œground-truth labelã€çš„æ¦‚çŽ‡ã€‚ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œå¿½ç•¥äº†på’Œqåœ¨example xä¸Šçš„ç›¸å…³æ€§ã€‚

ç›®æ ‡å‡½æ•°ï¼šã€Œæœ€å°åŒ–äº¤å‰ç†µã€ã€‚å› ä¸ºäº¤å‰ç†µè¡¡é‡çš„æ˜¯ä¸¤ä¸ªåˆ†å¸ƒï¼ˆpå’Œqï¼‰çš„ç›¸ä¼¼æ€§ï¼Œæœ€å°åŒ–ç›®æ ‡å‡½æ•°æ˜¯ä¸ºäº†è®©é¢„æµ‹çš„labelæ¦‚çŽ‡åˆ†å¸ƒp(k|x)ï¼ˆå³ä¾‹å¦‚ä¸Šé¢çš„softmaxçš„è¾“å‡ºï¼‰å’Œground-truth labelçš„æ¦‚çŽ‡åˆ†å¸ƒq(k|x)å°½å¯èƒ½çš„æŽ¥è¿‘ã€‚ã€Œæœ€å°åŒ–äº¤å‰ç†µã€ä¹Ÿç­‰ä»·ä¸ºã€Œæœ€å¤§åŒ–ä¼¼ç„¶å‡½æ•°ã€ã€‚ä½†æ˜¯æˆ‘ä»¬éœ€è¦å¯¹è¿™ä¸ªç›®æ ‡å‡½æ•°è¿›è¡Œäº†æ”¹è¿›ã€‚å› ä¸ºåœ¨å•ç±»æƒ…å†µä¸‹ï¼Œå•ä¸€çš„äº¤å‰ç†µå¯¼è‡´æ ·æœ¬å±žäºŽæŸä¸ªç±»åˆ«çš„æ¦‚çŽ‡éžå¸¸å¤§ï¼Œæ¨¡åž‹å¤ªè¿‡ä¸Žè‡ªä¿¡è‡ªå·±çš„åˆ¤æ–­ã€‚è¿™æ ·ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆï¼Œæ­¤å¤–è¿˜ä¼šé™ä½Žæ¨¡åž‹çš„é€‚åº”èƒ½åŠ›ã€‚ä¸ºäº†é¿å…æ¨¡åž‹è¿‡äºŽè‡ªä¿¡ï¼Œå¼•å…¥äº†ä¸€ä¸ªç‹¬ç«‹äºŽæ ·æœ¬åˆ†å¸ƒçš„å˜é‡u(k)ï¼Œè¿™ç›¸å½“äºŽåœ¨ground-truth distributionä¸­åŠ å…¥äº†å™ªå£°ï¼Œç»„æˆä¸€ä¸ªæ–°çš„åˆ†å¸ƒã€‚åœ¨å®žéªŒä¸­ï¼Œä½¿ç”¨çš„æ˜¯å‡åŒ€åˆ†å¸ƒ(uniform distribution)ä»£æ›¿äº†u(k)
> we propose a mechanism for encouraging the model to be less confident. While this may not be desired if the goal is to maximize the log-likelihood of training labels, it does regularize the model and makes it more adaptable â€¦â€¦ we refer to this
change in ground-truth label distribution as label-smoothing regularization, or LSR.
